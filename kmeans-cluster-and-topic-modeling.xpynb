{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kmeans-cluster-and-topic-modeling.xpynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"metadata":{"_uuid":"cdbef80edb46e7f336491a700dce38e074398784","_cell_guid":"5a18aefa-1518-4d43-abc2-b1fa9051d7b5","id":"_QpbURobkj6S","colab_type":"text"},"cell_type":"markdown","source":["# Introduction\n","In this kernal, I will use TF-IDF to vectorize the [articles data](https://www.kaggle.com/snapcrack/all-the-news/data) and cluster them. \n","Then, I will make paper recommendation."]},{"metadata":{"_uuid":"cfb448e8b9beb8d8a857da15376730dd8d0c628f","_cell_guid":"c94c0f3d-5b5b-42f5-b4c9-5ddc2c3c5af1","id":"J2xhwGlXkj6V","colab_type":"text"},"cell_type":"markdown","source":["**1. Input data**"]},{"metadata":{"_uuid":"947abb51738a2c42e9bd1b465720bd624605ea06","_cell_guid":"ae1fbc7a-e384-4199-8f36-f1d1447bf786","id":"iUmEv-MVkj6X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":897},"outputId":"1d5f8d06-d29d-4c37-d92e-07293bf71ddc","executionInfo":{"status":"error","timestamp":1550396822197,"user_tz":-330,"elapsed":2029,"user":{"displayName":"Ashish Salunkhe","photoUrl":"https://lh5.googleusercontent.com/-JA8wS1A42o8/AAAAAAAAAAI/AAAAAAAACpw/8iNsa5IGzj8/s64/photo.jpg","userId":"03884226030778664360"}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd \n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","text = pd.read_csv('../input/articles1.csv')\n","text.head()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-add2b961ff74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/articles1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/articles1.csv' does not exist"]}]},{"metadata":{"_uuid":"07466665856dc0b0a0d89d7e50adf4da423ca315","_cell_guid":"6d997a92-0d16-41dc-89b8-6901b535af17","id":"k69Ad4J-kj6e","colab_type":"text"},"cell_type":"markdown","source":["**2. Using TF-IDF vectorize the articles**\n","\n","[Introduction](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to TF-IDF"]},{"metadata":{"_uuid":"c43305078269683f780d6b2cf8c35efd20f5f9d4","_cell_guid":"ee7442ad-89da-493c-959f-2d0b7e3c9a40","id":"_OCiMGe-kj6f","colab_type":"code","colab":{}},"cell_type":"code","source":["text_content = text['content']\n","vector = TfidfVectorizer(stop_words = 'english')\n","tfidf = vector.fit_transform(text_content)\n","text_content.head()"],"execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f07b0f508af44fe7df95ec2b8540745d4db61dd6","_cell_guid":"f1ea7f69-3851-447e-8c2c-cbd3c474b15d","id":"g03j2vfikj6i","colab_type":"text"},"cell_type":"markdown","source":["**3. Using elbow method to decide cluster number**\n","\n","Introduction to [elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)"]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"3j5Zg2ESkj6k","colab_type":"code","colab":{}},"cell_type":"code","source":["K = range(1,15)\n","SSE = []\n","for k in K:\n","    kmeans = MiniBatchKMeans(n_clusters = k,batch_size = 300)\n","    kmeans.fit(tfidf)\n","    SSE.append(kmeans.inertia_)\n","    \n","import matplotlib.pyplot as plt\n","plt.plot(K,SSE,'bx-')\n","plt.title('Elbow Method')\n","plt.xlabel('cluster numbers')\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ff2c3b75655ac0b3328820d7adb7414079e5a8ca","_cell_guid":"4aa9e2e3-7f2a-42e1-ad83-1554af72222a","id":"Qj1KNoUfkj6p","colab_type":"text"},"cell_type":"markdown","source":["**5. Using MiniBatchKMean to cluster**\n","\n","[Comparison of the K-Means and MiniBatchKMeans clustering algorithms](http://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py)"]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","id":"zDg1TAymkj6q","colab_type":"code","colab":{}},"cell_type":"code","source":["k = 4\n","kmeans = MiniBatchKMeans(n_clusters = k)\n","kmeans.fit(tfidf)\n","centers = kmeans.cluster_centers_.argsort()[:,::-1]\n","terms = vector.get_feature_names()\n","\n","for i in range(0,k):\n","    word_list=[]\n","    print(\"cluster%d:\"% i)\n","    for j in centers[i,:15]:\n","        word_list.append(terms[j])\n","    print(word_list) \n"],"execution_count":0,"outputs":[]},{"metadata":{"_uuid":"13f971873eb2d912b5e1189a8592bf2be97c2838","_cell_guid":"b372fe7e-022d-4c9a-8e57-573cbccb7a64","id":"KAhgpKwkkj6v","colab_type":"text"},"cell_type":"markdown","source":["**6. Article Recommendation**\n","\n","Since we had vectorize the articles by TF-IDF, we only need to compare articles by comparing their vectors. Bigger inner product of two vectors means they shares more similar information. Here we take the first article in artciles3.csv--Alton Sterling’s son: ’Everyone needs to protest the right way, with peace’ as example."]},{"metadata":{"_uuid":"9236750bbf075652b5cb03ed4a88a84c6f991ac2","_cell_guid":"af9ec5de-0378-4e74-97f2-76c5829559a1","id":"9IKd5dNkkj6w","colab_type":"code","colab":{}},"cell_type":"code","source":["similarity = np.dot(tfidf[0],np.transpose(tfidf))\n","x = np.array(similarity.toarray()[0])\n","print(text['title'][0])\n","print('\\nsimiliar papers:')\n","print('\\n'.join(text['title'].loc[np.argsort(x)[-7:-2]]))\n"],"execution_count":0,"outputs":[]},{"metadata":{"_uuid":"9f53f5a90394a45fa50610d65c2c718ae151cbf9","_cell_guid":"072d722c-169b-4720-8891-460d31fa95e2","id":"WBCBJV_Bkj61","colab_type":"text"},"cell_type":"markdown","source":["**7. Topic modeling **\n","\n","Here I use NMF instead of LDA because LDA's calculation is time-consuming. \n","\n","The major topics consist of politics, society, finance and internetional affairs, which is quite similiar to our cluster resu"]},{"metadata":{"_uuid":"841f54807d352edb5e940e51c49d7e3614a27814","_cell_guid":"5475b769-2ed7-4d15-9283-802d1a28cf98","id":"DVvVoysNkj62","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.decomposition import NMF\n","\n","nmf  = NMF(n_components = 4)\n","nmf.fit(tfidf)\n","for i in range(0,k):\n","    word_list=[]\n","    print(\"Topic%d:\"% i)\n","    for j in nmf.components_.argsort()[i,-16:-1]:\n","        word_list.append(terms[j])\n","    print(word_list)"],"execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0768e23df87e5b0ba89f1e070331689d90356e92","_cell_guid":"28832dc3-4b5f-416c-b9df-fe2130a1358c","id":"fNZqqEuGkj66","colab_type":"text"},"cell_type":"markdown","source":[""]}]}